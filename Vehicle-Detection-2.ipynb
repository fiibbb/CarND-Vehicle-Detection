{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage.measurements import label\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DataStore():\n",
    "    def __init__(self):\n",
    "        \n",
    "        print('Loading data...')\n",
    "        t1 = time.time()\n",
    "        \n",
    "        self.car_fnames = glob.glob('images/vehicles/*/*.png')\n",
    "        self.scn_fnames = glob.glob('images/non-vehicles/*/*.png')\n",
    "        self.car_images = [mpimg.imread(fname) for fname in self.car_fnames]\n",
    "        self.scn_images = [mpimg.imread(fname) for fname in self.scn_fnames]\n",
    "\n",
    "        t2 = time.time()\n",
    "        print('Loaded all data in {} seconds'.format(round(t2-t1), 2))\n",
    "\n",
    "        \n",
    "ds = DataStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class VehicleDetection():\n",
    "\n",
    "    \n",
    "    def __init__(self, data_store):\n",
    "        \n",
    "        self.color_space = 'HLS'\n",
    "\n",
    "        self.feat_spatial = False\n",
    "        self.feat_hist = False\n",
    "        self.feat_hog = True\n",
    "        \n",
    "        self.spatial_size = (32, 32)\n",
    "        \n",
    "        self.hist_bins = 32\n",
    "        self.hist_channels = [0, 1, 2]\n",
    "        \n",
    "        self.orient = 9\n",
    "        self.pix_per_cell = 8\n",
    "        self.cell_per_block = 2\n",
    "        self.hog_channels = [0, 1, 2]\n",
    "\n",
    "        self.window_config = [\n",
    "            {\n",
    "                'y_start_stop': [400, None],\n",
    "                'xy_window': (80, 80),\n",
    "                'xy_overlap': (0.8, 0.8)\n",
    "            },\n",
    "            {\n",
    "                'y_start_stop': [400, None],\n",
    "                'xy_window': (120, 120),\n",
    "                'xy_overlap': (0.8, 0.8)\n",
    "            },\n",
    "            {\n",
    "                'y_start_stop': [400, None],\n",
    "                'xy_window': (160, 160),\n",
    "                'xy_overlap': (0.8, 0.8)\n",
    "            },\n",
    "            {\n",
    "                'y_start_stop': [400, None],\n",
    "                'xy_window': (24, 240),\n",
    "                'xy_overlap': (0.8, 0.8)\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        self.find_box_config = [\n",
    "            {\n",
    "                'ystart': 400,\n",
    "                'ystop': 500,\n",
    "                'scale': 1\n",
    "            },\n",
    "            {\n",
    "                'ystart': 400,\n",
    "                'ystop': 600,\n",
    "                'scale': 1.5\n",
    "            },\n",
    "            {\n",
    "                'ystart': 400,\n",
    "                'ystop': 720,\n",
    "                'scale': 2\n",
    "            }            \n",
    "        ]\n",
    "        \n",
    "        t1 = time.time()\n",
    "        print('Extracting features...')\n",
    "        \n",
    "        self.car_images = [self.convert_color(img) for img in data_store.car_images]\n",
    "        self.scn_images = [self.convert_color(img) for img in data_store.scn_images]\n",
    "        \n",
    "        car_features = self.extract_features_for_imgs(self.car_images)\n",
    "        scn_features = self.extract_features_for_imgs(self.scn_images)\n",
    "\n",
    "        unscaled_X = np.vstack((car_features, scn_features)).astype(np.float64)\n",
    "        self.scaler = StandardScaler().fit(unscaled_X)\n",
    "        \n",
    "        self.X = self.scaler.transform(unscaled_X)\n",
    "        self.y = np.hstack((np.ones(len(car_features)), np.zeros(len(scn_features))))\n",
    "        \n",
    "        t2 = time.time()\n",
    "        print('Extracted all features in {} seconds'.format(round(t2-t1), 2))\n",
    "\n",
    "        \n",
    "        t3 = time.time()\n",
    "        print('Training SVM...')\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=np.random.randint(0, 100))\n",
    "        self.svc = LinearSVC()\n",
    "        self.svc.fit(self.X_train, self.y_train)\n",
    "        score = self.svc.score(self.X_test, self.y_test)\n",
    "        \n",
    "        t4 = time.time()\n",
    "        print('Trained SVM in {} seconds with {} accuracy'.format(round(t4-t3, 2), score))\n",
    "\n",
    "        \n",
    "    def draw_boxes(self, img, boxes, color=(255,0,0), thick=6):\n",
    "        imcopy = np.copy(img)\n",
    "        for box in boxes:\n",
    "            cv2.rectangle(imcopy, box[0], box[1], color, thick)\n",
    "        return imcopy\n",
    "    \n",
    "        \n",
    "    def convert_color(self, img):\n",
    "        if self.color_space == 'HSV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif self.color_space == 'LUV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif self.color_space == 'HLS':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif self.color_space == 'YUV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif self.color_space == 'YCrCb':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        else:\n",
    "            return np.copy(img)\n",
    "        \n",
    "    \n",
    "    def get_bin_spatial(self, img):\n",
    "        return cv2.resize(img, self.spatial_size).ravel()\n",
    "        \n",
    "        \n",
    "    def get_color_hist(self, img):\n",
    "        return np.concatenate([np.histogram(img[:,:,ch], bins=self.hist_bins, range=self.bins_range)[0] for ch in self.hist_channels])\n",
    "        \n",
    "    \n",
    "    def get_hog(self, img, feature_vector=True):\n",
    "        return hog(img, orientations=self.orient,\n",
    "                   pixels_per_cell=(self.pix_per_cell, self.pix_per_cell),\n",
    "                   cells_per_block=(self.cell_per_block, self.cell_per_block), \n",
    "                   transform_sqrt=True,\n",
    "                   visualise=False,\n",
    "                   feature_vector=feature_vector)\n",
    "    \n",
    "    \n",
    "    def extract_features_for_img(self, img):\n",
    "        features = []\n",
    "        if self.feat_spatial:\n",
    "            features.append(self.get_bin_spatial(img))\n",
    "        if self.feat_hist:\n",
    "            features.append(self.get_color_hist(img))\n",
    "        if self.feat_hog:\n",
    "            hog_features = []\n",
    "            for ch in self.hog_channels:\n",
    "                hog_features.extend(self.get_hog(img[:,:,ch]))\n",
    "            features.append(hog_features)\n",
    "        return np.concatenate(features)\n",
    "    \n",
    "    \n",
    "    def extract_features_for_imgs(self, imgs):\n",
    "        return [self.extract_features_for_img(img) for img in imgs]\n",
    "    \n",
    "    \n",
    "    def slide_window(self, img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                     xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "        # If x and/or y start/stop positions not defined, set to image size\n",
    "        if x_start_stop[0] == None:\n",
    "            x_start_stop[0] = 0\n",
    "        if x_start_stop[1] == None:\n",
    "            x_start_stop[1] = img.shape[1]\n",
    "        if y_start_stop[0] == None:\n",
    "            y_start_stop[0] = 0\n",
    "        if y_start_stop[1] == None:\n",
    "            y_start_stop[1] = img.shape[0]\n",
    "        # Compute the span of the region to be searched    \n",
    "        xspan = x_start_stop[1] - x_start_stop[0]\n",
    "        yspan = y_start_stop[1] - y_start_stop[0]\n",
    "        # Compute the number of pixels per step in x/y\n",
    "        nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "        ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "        # Compute the number of windows in x/y\n",
    "        nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "        ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "        nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "        ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "        # Initialize a list to append window positions to\n",
    "        window_list = []\n",
    "        # Loop through finding x and y window positions\n",
    "        # Note: you could vectorize this step, but in practice\n",
    "        # you'll be considering windows one by one with your\n",
    "        # classifier, so looping makes sense\n",
    "        for ys in range(ny_windows):\n",
    "            for xs in range(nx_windows):\n",
    "                # Calculate window position\n",
    "                startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "                endx = startx + xy_window[0]\n",
    "                starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "                endy = starty + xy_window[1]\n",
    "                \n",
    "                # Append window position to list\n",
    "                window_list.append(((startx, starty), (endx, endy)))\n",
    "        # Return the list of windows\n",
    "        return window_list\n",
    "\n",
    "    \n",
    "    def search_windows(self, img, windows):\n",
    "        hot_windows = []\n",
    "        for window in windows:\n",
    "            # Extract sub-image using window and resize to 64x64\n",
    "            sub_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))\n",
    "            # Extract feature from sub-image\n",
    "            features = self.extract_features_for_img(sub_img)\n",
    "            # Scale extracted features to be fed to classifier\n",
    "            features = self.scaler.transform(np.array(features).reshape(1, -1))\n",
    "            # Predict if sub-image is a car using classifier\n",
    "            prediction = self.svc.predict(features)\n",
    "            if prediction == 1:\n",
    "                hot_windows.append(window)\n",
    "        return hot_windows\n",
    "    \n",
    "    \n",
    "    def multiplex_windows(self, img):\n",
    "        windows = []\n",
    "        for cfg in self.window_config:\n",
    "            windows += self.slide_window(img,\n",
    "                                         y_start_stop=cfg['y_start_stop'],\n",
    "                                         xy_window=cfg['xy_window'],\n",
    "                                         xy_overlap=cfg['xy_overlap'])\n",
    "        return windows\n",
    "\n",
    "    \n",
    "    def process_image(self, img):\n",
    "        draw_img = np.copy(img)\n",
    "        img = self.convert_color(img)\n",
    "        windows = self.multiplex_windows(img)\n",
    "        hot_windows = self.search_windows(img, windows)\n",
    "        draw_img = self.draw_boxes(draw_img, hot_windows)\n",
    "        return draw_img\n",
    "\n",
    "    \n",
    "    def process_image2(self, img, threshold=1):\n",
    "        \n",
    "        # Copy image and convert color space\n",
    "        draw_img = np.copy(img)\n",
    "        img = self.convert_color(img)\n",
    "        \n",
    "        # Search for hot boxes\n",
    "        windows = self.multiplex_windows(img)\n",
    "        boxes = self.search_windows(img, windows)\n",
    "\n",
    "        # Convert hot boxes to heatmap\n",
    "        heatmap = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "        for box in boxes:\n",
    "            heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "        heatmap[heatmap <= threshold] = 0\n",
    "        heatmap = np.clip(heatmap, 0, 255)\n",
    "        \n",
    "        # Draw thresholded boxes on original image\n",
    "        labels = label(heatmap)\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(draw_img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "        \n",
    "        return draw_img\n",
    "\n",
    "    \n",
    "    def find_boxes(self, img, ystart, ystop, scale, cells_per_step=2):        \n",
    "\n",
    "        img_tosearch = img[ystart:ystop,:,:]\n",
    "        ctrans_tosearch = self.convert_color(img_tosearch)\n",
    "\n",
    "        if scale != 1:\n",
    "            imshape = ctrans_tosearch.shape\n",
    "            ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "            \n",
    "        ch0 = ctrans_tosearch[:,:,0]\n",
    "        ch1 = ctrans_tosearch[:,:,1]\n",
    "        ch2 = ctrans_tosearch[:,:,2]\n",
    "    \n",
    "        # Define blocks and steps as above\n",
    "        nxblocks = (ch0.shape[1] // self.pix_per_cell) - 1\n",
    "        nyblocks = (ch0.shape[0] // self.pix_per_cell) - 1 \n",
    "        nfeat_per_block = self.orient * self.cell_per_block ** 2\n",
    "        # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "        window = 64\n",
    "        nblocks_per_window = (window // self.pix_per_cell)-1 \n",
    "        \n",
    "        # Instead of overlap, use how many cells to step\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "        \n",
    "        # Compute individual channel HOG features for the entire image\n",
    "        hog0 = self.get_hog(ch0, feature_vector=False)\n",
    "        hog1 = self.get_hog(ch1, feature_vector=False)\n",
    "        hog2 = self.get_hog(ch2, feature_vector=False)\n",
    "        \n",
    "        hot_boxes = []\n",
    "        \n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                                \n",
    "                ypos = yb * cells_per_step\n",
    "                xpos = xb * cells_per_step\n",
    "                # Extract HOG for this patch\n",
    "                hog_feat0 = hog0[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_features = np.hstack((hog_feat0, hog_feat1, hog_feat2))\n",
    "        \n",
    "                xleft = xpos * self.pix_per_cell\n",
    "                ytop = ypos * self.pix_per_cell\n",
    "    \n",
    "                # Extract the image patch\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "                \n",
    "                # Get color features\n",
    "                # spatial_features = self.get_bin_spatial(subimg)\n",
    "                # hist_features = self.get_color_hist(subimg)\n",
    "    \n",
    "                # Scale features and make a prediction\n",
    "                test_features = self.scaler.transform(hog_features)    \n",
    "                #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))\n",
    "                test_prediction = self.svc.predict(test_features)\n",
    "\n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    box = ((xbox_left, ytop_draw+ystart), (xbox_left+win_draw,ytop_draw+win_draw+ystart))\n",
    "                    hot_boxes.append(box)\n",
    "                    \n",
    "        return hot_boxes\n",
    "    \n",
    "    \n",
    "    def process_image3(self, img, threshold=2):\n",
    "        draw_img = np.copy(img)\n",
    "        \n",
    "        boxes = []\n",
    "        for cfg in self.find_box_config:\n",
    "            boxes += self.find_boxes(img, cfg['ystart'], cfg['ystop'], cfg['scale']) \n",
    "\n",
    "        heatmap = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "        for box in boxes:\n",
    "            heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "        heatmap[heatmap <= threshold] = 0\n",
    "        heatmap = np.clip(heatmap, 0, 255)\n",
    "        \n",
    "        # Draw thresholded boxes on original image\n",
    "        labels = label(heatmap)\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(draw_img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "        \n",
    "        return draw_img\n",
    "        \n",
    "    \n",
    "    \n",
    "vd = VehicleDetection(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#img = vd.process_image2(mpimg.imread('test_images/test5.jpg', 2))\n",
    "img = mpimg.imread('test_images/test4.jpg')\n",
    "img = vd.process_image3(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clip = VideoFileClip('project_video.mp4')\n",
    "new_clip = clip.fl_image(vd.process_image3)\n",
    "%time new_clip.write_videofile('test_output.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"test_output.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
