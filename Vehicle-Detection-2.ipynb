{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from skimage.feature import hog\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded all data in 33 seconds\n"
     ]
    }
   ],
   "source": [
    "class DataStore():\n",
    "    def __init__(self):\n",
    "        \n",
    "        print('Loading data...')\n",
    "        t1 = time.time()\n",
    "        \n",
    "        self.car_fnames = glob.glob('images/vehicles/*/*.png')\n",
    "        self.scn_fnames = glob.glob('images/non-vehicles/*/*.png')\n",
    "        self.car_images = [mpimg.imread(fname) for fname in self.car_fnames]\n",
    "        self.scn_images = [mpimg.imread(fname) for fname in self.scn_fnames]\n",
    "\n",
    "        t2 = time.time()\n",
    "        print('Loaded all data in {} seconds'.format(round(t2-t1), 2))\n",
    "\n",
    "        \n",
    "ds = DataStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Extracted all features in 65 seconds\n",
      "Training SVM...\n"
     ]
    }
   ],
   "source": [
    "class VehicleDetection():\n",
    "\n",
    "    \n",
    "    def __init__(self, data_store):\n",
    "        \n",
    "        self.color_space = 'HLS'\n",
    "\n",
    "        self.feat_spatial = False\n",
    "        self.feat_hist = False\n",
    "        self.feat_hog = True\n",
    "        \n",
    "        self.spatial_size = (32, 32)\n",
    "        \n",
    "        self.hist_bins = 32\n",
    "        self.hist_channels = [0, 1, 2]\n",
    "        \n",
    "        self.orient = 9\n",
    "        self.pix_per_cell = 8\n",
    "        self.cell_per_block = 2\n",
    "        self.hog_channels = [0, 1, 2]\n",
    "\n",
    "        t1 = time.time()\n",
    "        print('Extracting features...')\n",
    "        \n",
    "        self.car_images = [self.convert_color(img) for img in data_store.car_images]\n",
    "        self.scn_images = [self.convert_color(img) for img in data_store.scn_images]\n",
    "        \n",
    "        car_features = self.extract_features_for_imgs(self.car_images)\n",
    "        scn_features = self.extract_features_for_imgs(self.scn_images)\n",
    "\n",
    "        unscaled_X = np.vstack((car_features, scn_features)).astype(np.float64)\n",
    "        self.scaler = StandardScaler().fit(unscaled_X)\n",
    "        \n",
    "        self.X = self.scaler.transform(unscaled_X)\n",
    "        self.y = np.hstack((np.ones(len(car_features)), np.zeros(len(scn_features))))\n",
    "        \n",
    "        t2 = time.time()\n",
    "        print('Extracted all features in {} seconds'.format(round(t2-t1), 2))\n",
    "\n",
    "        \n",
    "        t3 = time.time()\n",
    "        print('Training SVM...')\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=np.random.randint(0, 100))\n",
    "        self.svc = LinearSVC()\n",
    "        self.svc.fit(self.X_train, self.y_train)\n",
    "        score = vd.svc.score(vd.X_test, vd.y_test)\n",
    "        \n",
    "        t4 = time.time()\n",
    "        print('Trained SVM in {} seconds with {} accuracy'.format(round(t4-t3, 2), score))\n",
    "\n",
    "        \n",
    "    def draw_boxes(self, img, boxes, color=(255,0,0), thick=6):\n",
    "        imcopy = np.copy(img)\n",
    "        for box in boxes:\n",
    "            cv2.rectangle(imcopy, box[0], box[1], color, thick)\n",
    "        return imcopy\n",
    "    \n",
    "        \n",
    "    def convert_color(self, img):\n",
    "        if self.color_space == 'HSV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif self.color_space == 'LUV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif self.color_space == 'HLS':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif self.color_space == 'YUV':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif self.color_space == 'YCrCb':\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        else:\n",
    "            return np.copy(img)\n",
    "        \n",
    "    \n",
    "    def get_bin_spatial(self, img):\n",
    "        return cv2.resize(img, self.spatial_size).ravel()\n",
    "        \n",
    "        \n",
    "    def get_color_hist(self, img):\n",
    "        return np.concatenate([np.histogram(img[:,:,ch], bins=self.hist_bins, range=self.bins_range)[0] for ch in self.hist_channels])\n",
    "        \n",
    "    \n",
    "    def get_hog(self, img):\n",
    "        return hog(img, orientations=self.orient,\n",
    "                   pixels_per_cell=(self.pix_per_cell, self.pix_per_cell),\n",
    "                   cells_per_block=(self.cell_per_block, self.cell_per_block), \n",
    "                   transform_sqrt=True,\n",
    "                   visualise=False,\n",
    "                   feature_vector=True)\n",
    "    \n",
    "    \n",
    "    def extract_features_for_img(self, img):\n",
    "        features = []\n",
    "        if self.feat_spatial:\n",
    "            features.append(self.get_bin_spatial(img))\n",
    "        if self.feat_hist:\n",
    "            features.append(self.get_color_hist(img))\n",
    "        if self.feat_hog:\n",
    "            hog_features = []\n",
    "            for ch in self.hog_channels:\n",
    "                hog_features.extend(self.get_hog(img[:,:,ch]))\n",
    "            features.append(hog_features)\n",
    "        return np.concatenate(features)\n",
    "    \n",
    "    \n",
    "    def extract_features_for_imgs(self, imgs):\n",
    "        return [self.extract_features_for_img(img) for img in imgs]\n",
    "    \n",
    "    \n",
    "    def slide_window(self, img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                     xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "        # If x and/or y start/stop positions not defined, set to image size\n",
    "        if x_start_stop[0] == None:\n",
    "            x_start_stop[0] = 0\n",
    "        if x_start_stop[1] == None:\n",
    "            x_start_stop[1] = img.shape[1]\n",
    "        if y_start_stop[0] == None:\n",
    "            y_start_stop[0] = 0\n",
    "        if y_start_stop[1] == None:\n",
    "            y_start_stop[1] = img.shape[0]\n",
    "        # Compute the span of the region to be searched    \n",
    "        xspan = x_start_stop[1] - x_start_stop[0]\n",
    "        yspan = y_start_stop[1] - y_start_stop[0]\n",
    "        # Compute the number of pixels per step in x/y\n",
    "        nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "        ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "        # Compute the number of windows in x/y\n",
    "        nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "        ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "        nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "        ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "        # Initialize a list to append window positions to\n",
    "        window_list = []\n",
    "        # Loop through finding x and y window positions\n",
    "        # Note: you could vectorize this step, but in practice\n",
    "        # you'll be considering windows one by one with your\n",
    "        # classifier, so looping makes sense\n",
    "        for ys in range(ny_windows):\n",
    "            for xs in range(nx_windows):\n",
    "                # Calculate window position\n",
    "                startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "                endx = startx + xy_window[0]\n",
    "                starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "                endy = starty + xy_window[1]\n",
    "                \n",
    "                # Append window position to list\n",
    "                window_list.append(((startx, starty), (endx, endy)))\n",
    "        # Return the list of windows\n",
    "        return window_list\n",
    "\n",
    "    \n",
    "    def search_windows(self, img, windows):\n",
    "        hot_windows = []\n",
    "        for window in windows:\n",
    "            # Extract sub-image using window and resize to 64x64\n",
    "            sub_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))\n",
    "            # Extract feature from sub-image\n",
    "            features = extract_features_for_img(sub_img)\n",
    "            # Scale extracted features to be fed to classifier\n",
    "            features = self.scaler.transform(np.array(features).reshape(1, -1))\n",
    "            # Predict if sub-image is a car using classifier\n",
    "            prediction = self.svc.predict(features)\n",
    "            if prediction == 1:\n",
    "                hot_windows.append(window)\n",
    "        return hot_windows\n",
    "    \n",
    "    \n",
    "    def multiplex_windows(self, img):\n",
    "        windows = []\n",
    "        for cfg in self.window_config:\n",
    "            windows += self.slide_window(img,\n",
    "                                         y_start_stop=cfg['y_start_stop'],\n",
    "                                         xy_window=cfg['xy_window'],\n",
    "                                         xy_overlap=cfg['xy_overlap'])\n",
    "        return windows\n",
    "\n",
    "    \n",
    "    def process_image(self, img):\n",
    "        draw_img = np.copy(img)\n",
    "        img = self.convert_color(img)\n",
    "        windows = self.multiplex_windows(img)\n",
    "        hot_windows = self.search_windows(img, windows)\n",
    "        draw_img = self.draw_boxes(draw_img, hot_windows)\n",
    "        return draw_img\n",
    "\n",
    "    \n",
    "vd = VehicleDetection(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = vd.process_image(mpimg.imread('test_images/test1.jpg'))\n",
    "plt.imshow(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
